}
z <- 4
x + g(x)
}
z<-10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
colours <- factor(c("red","blue","red","white", "silver", "red", "white", "silver", "red","red","white","silver","silver"), levels=c("red","blue","white","silver","black"))
table(colours)
colours2 <-c("red","blue","red","white", "silver","red","white","silver", "red","red","white","silver")
# Now, make the table
table(colours2)
## Self-Test Question 2.
car.type <- factor(c("saloon","saloon","hatchback", "saloon","convertible","hatchback","convertible", "saloon", "hatchback","saloon", "saloon", "saloon", "hatchback"), levels=c("saloon","hatchback","convertible"))
table(car.type, colours)
crosstab <- table(car.type,colours)
## Self-Test Question 3.
engine <- ordered(c("1.1litre","1.3litre","1.1litre", "1.3litre","1.6litre","1.3litre","1.6litre", "1.1litre","1.3litre","1.1litre", "1.1litre", "1.3litre","1.3litre"), levels=c("1.1litre","1.3litre","1.6litre"))
engine > "1.1litre"
apply(crosstab,1,which.max)
levels(engine)
levels(colors)[which.max(crosstab[,1])]
levels(colours)[which.max(crosstab[,1])]
which.max(crosstab[,1])
matrix(3,3)
colnames(colours)[which.max(crosstab[,1])]
colnames(colours)[which.max(crosstab[,1])]
colnames(crosstab)[which.max(crosstab[,1])]
colnames(crosstab)
which.max.name <- function(x){
return(names(x)[which.max(x)])
}
names(example) <- c("Leicester","Nottingham","Loughborough","Birmingham","Coventry")
example
which.max.name <- function(x){
return(names(x)[which.max(x)])
}
names(example) <- c("Leicester","Nottingham","Loughborough","Birmingham","Coventry")
names(example) <- c("Leicester","Nottingham", "Loughborough","Birmingham","Coventry")
which.max.name <- function(x) {
return(names(x)[which.max(x)])}
names(example) <- c("Leicester","Nottingham", "Loughborough","Birmingham","Coventry")
example
which.max.name(crosstab)
which.max.name <- function(x){
return(names(x)[which.max(x)])
}
which.max.name(crosstab[,1])
which.max.name(crosstab[1,])
apply(crosstab,1,which.max.name(crosstab))
apply(crosstab,1,which.max.name)
apply(crosstab,2,which.max.name)
most.popular <- list(colour = apply(crosstab,1,which.max.name), type = apply(crosstab,2,which.max.name))
most.popular
table(car.type,colours)
new.sales.data <- function(colours,car.type){
xtab <- table(car.type,colours)
result <- list(colour=apply(xtab,1,which,max.name),
type=apply(xtab,2,which.max.name),
total=sum(xtab))
class(result) <- "sales.data"
return(result)}
}
new.sales.data <- function(colours,car.type){
xtab <- table(car.type,colours)
result <- list(colour=apply(xtab,1,which,max.name),
type=apply(xtab,2,which.max.name),
total=sum(xtab))
class(result) <- "sales.data"
return(result)
}
this.week <- new.sales.data(colours,car.type)
this.week <- new.sales.data(colours,car.type)
this.week
colours <- factor(c("red","blue","red","white", "silver", "red", "white", "silver", "red","red","white","silver","silver"), levels=c("red","blue","white","silver","black"))
table(colours)
colours2 <-c("red","blue","red","white", "silver","red","white","silver", "red","red","white","silver")
# Now, make the table
table(colours2)
## Self-Test Question 2.
car.type <- factor(c("saloon","saloon","hatchback", "saloon","convertible","hatchback","convertible", "saloon", "hatchback","saloon", "saloon", "saloon", "hatchback"), levels=c("saloon","hatchback","convertible"))
table(car.type, colours)
crosstab <- table(car.type,colours)
## Self-Test Question 3.
engine <- ordered(c("1.1litre","1.3litre","1.1litre", "1.3litre","1.6litre","1.3litre","1.6litre", "1.1litre","1.3litre","1.1litre", "1.1litre", "1.3litre","1.3litre"), levels=c("1.1litre","1.3litre","1.6litre"))
engine > "1.1litre"
## Self-Test Question 5.
apply(crosstab,1,which.max)
## Self-Test Question 6.
levels(engine)
which.max(crosstab[,1])
levels(colours)[which.max(crosstab[,1])]
matrix(3,3)
colnames(crosstab)[which.max(crosstab[,1])]
colnames(crosstab)
which.max.name <- function(x){
return(names(x)[which.max(x)])
}
names(example) <- c("Leicester","Nottingham", "Loughborough","Birmingham","Coventry") # doesn't work
example x
which.max.name(example)
which.max.name(crosstab[,1])
which.max.name(crosstab[1,])
## Self-Test Question 7.
apply(crosstab,1,which.max.name)
apply(crosstab,2,which.max.name)
## Self-Test Question 8.
most.popular <- list(colour = apply(crosstab,1,which.max.name), type = apply(crosstab,2,which.max.name))
most.popular
new.sales.data <- function(colours,car.type){
xtab <- table(car.type,colours)
result <- list(colour=apply(xtab,1,which,max.name),
type=apply(xtab,2,which.max.name),
total=sum(xtab))
class(result) <- "sales.data"
return(result)
}
table(car.type,colours)
this.week <- new.sales.data(colours,car.type)
this.week
new.sales.data <- function(colours,car.type){
xtab <- table(car.type,colours)
result <- list(colour=apply(xtab,1,which.max.name),
type=apply(xtab,2,which.max.name),
total=sum(xtab))
class(result) <- "sales.data"
return(result)
}
table(car.type,colours)
this.week <- new.sales.data(colours,car.type)
this.week
names(example) <- c("Leicester","Nottingham", "Loughborough","Birmingham","Coventry") # doesn't work
table(car.type,colours)
this.week <- new.sales.data(colours,car.type)
this.week
this.week <- new.sales.data(colours,car.type)
new.sales.data <- function(colours,car.type){
xtab <- table(car.type,colours)
result <- list(colour=apply(xtab,1,which.max.name),
type=apply(xtab,2,which.max.name),
total=sum(xtab))
class(result) <- "sales.data"
return(result)
}
this.week <- new.sales.data(colours,car.type)
this.week
￼library(shiny)ui <- fluidPage()server <- function(input, output) {}shinyApp(ui = ui, server = server)
￼library(shiny)ui <- fluidPage()server <- function(input, output) {}shinyApp(ui = ui, server = server)
￼library(shiny)ui <- fluidPage()server <- function(input, output) {}shinyApp(ui = ui, server = server)
shinyApp(ui = ui, server = server)
￼library(shiny)ui <- fluidPage()server <- function(input, output) {}shinyApp(ui = ui, server = server)
￼library(shiny)ui <- fluidPage()server <- function(input, output) {}shinyApp(ui = ui, server = server)
￼library(shiny)ui <- fluidPage()server <- function(input, output) {}shinyApp(ui = ui, server = server)
library(shiny)
ui <- fluidPage()
server <- function(input, output) {}
shinyApp(ui = ui, server = server)
install.packages(shiny)
install.packages("shiny")
library(shiny)
ui <- fluidPage()
server <- function(input, output) {}
shinyApp(ui = ui, server = server)
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
geom_bar()
geom_bar
geom_map
p <- ggplot(mpg, aes(displ, hwy))
p + geom_point()
library(sparkR)
installed.packages("spark")
library(spark)
Sys.setenv(SPARK_HOME="/usr/local/spark-1.5.1-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"),"R","lib"), .libPaths()))
library(spark)
library(SparkR)
sc <- sparkR.init(master="local")
sqlContent <- sparkRSQL.init(sc)
DF <- createDataFrame(sqlContext, faithful)
sqlContext <- sparkRSQL.init(sc)
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
DF <- createDataFrame(sqlContext, faithful)
head(DF)
localDF <- data.frame(name=c("John", "Smith", "Sarah"), age=c(19, 23, 18))
df <- createDataFrame(sqlContext, localDF)
printSchema(df)
path <- file.path(Sys.getenv("SPARK_HOME"), "examples/src/main/resources/people.json")
peopleDF <- jsonFile(sqlContext, path)
printSchema(peopleDF)
registerTempTable(peopleDF, "people")
teenagers <- sql(sqlContext, "SELECT name FROM people WHERE age >= 13 AND age <= 19")
teenagersLocalDF <- collect(teenagers)
print(teenagersLocalDF)
?read.df
source('~/Country-lore-analysis-Germany/schema.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schema.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
library(SparkR)
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
sparkR.stop()
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
mySt <- read.df(sqlContext,
#"/home/dhaeb/dvl/data/dwd/kl/kl_total.csv",
"/Users/martinmac/Big_Data_Prak_Lani/data/kl/KL_Tageswerte_Beschreibung_Stationen4.txt",
"com.databricks.spark.csv",
klSchema,
header="true", delimiter = ";")
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"),"R","lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
Sys.setenv(SPARK_HOME="/usr/local/spark-1.5.1-bin-hadoop2.6")
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schema.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
sparkR.stop()
sparkR.stop()
library(SparkR)
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
mySt <- read.df(sqlContext,
#"/home/dhaeb/dvl/data/dwd/kl/kl_total.csv",
"/Users/martinmac/Big_Data_Prak_Lani/data/kl/KL_Tageswerte_Beschreibung_Stationen4.txt",
"com.databricks.spark.csv",
klSchema,
header="true", delimiter = ";")
mySt <- read.df(sqlContext,
"/Users/martinmac/Big_Data_Prak_Lani/data/kl/KL_Tageswerte_Beschreibung_Stationen4.txt",
"com.databricks.spark.csv",
klSchema,
header="true", delimiter = ";")
read.df(sqlContext = sqlContext, "3asdrgf", klSchema)
read.df(sqlContext = sqlContext, "3asdrgf", klSchema)
read.df(sqlContext = sqlContext, "3asdrgf", klSchema)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/november_frost_januar_nass.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/november_frost_januar_nass.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/november_frost_januar_nass.R', echo=TRUE)
sparkR.stop()
sparkR.stop()
sc <- sparkR.init(master="local", sparkPackages="com.databricks:spark-csv_2.10:1.2.0")
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
mySt <- read.df(sqlContext,
#"/home/dhaeb/dvl/data/dwd/kl/kl_total.csv",
"/Users/martinmac/Big_Data_Prak_Lani/data/kl/KL_Tageswerte_Beschreibung_Stationen4.txt",
"com.databricks.spark.csv",
klSchema,
header="true", delimiter = ";")
source('~/Big_Data_Prak_Lani/get_sparkR_in_rstudio.R', echo=TRUE)
source('~/Big_Data_Prak_Lani/get_sparkR_in_rstudio.R', echo=TRUE)
sparkR.stop()
sc <- sparkR.init(master="local", sparkPackages="com.databricks:spark-csv_2.10:1.2.0")
source('~/Big_Data_Prak_Lani/get_sparkR_in_rstudio.R', echo=TRUE)
source('~/Big_Data_Prak_Lani/get_sparkR_in_rstudio.R', echo=TRUE)
source('~/Big_Data_Prak_Lani/get_sparkR_in_rstudio.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
DF <- createDataFrame(sqlContext, faithful)
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
DF <- createDataFrame(sqlContext, faithful)
head(DF)
library(SparkR)
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
DF <- createDataFrame(sqlContext, faithful)
head(DF)
DF <- createDataFrame(sqlContext, faithful)
head(DF)
Sys.setenv(SPARK_HOME="/usr/local/spark-1.5.1-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"),"R","lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local")
sqlContext <- sparkRSQL.init(sc)
DF <- createDataFrame(sqlContext, faithful)
head(DF)
localDF <- data.frame(name=c("John", "Smith", "Sarah"), age=c(19, 23, 18))
df <- createDataFrame(sqlContext, localDF)
printSchema(df)
path <- file.path(Sys.getenv("SPARK_HOME"), "examples/src/main/resources/people.json")
peopleDF <- jsonFile(sqlContext, path)
printSchema(peopleDF)
registerTempTable(peopleDF, "people")
teenagers <- sql(sqlContext, "SELECT name FROM people WHERE age >= 13 AND age <= 19")
teenagersLocalDF <- collect(teenagers)
print(teenagersLocalDF)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss_PRE.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss_SS.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss_PRE_NEG.R', echo=TRUE)
a_SON
a_TEMP
a_SCH
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
inDf <- read.df(sqlContext,
path = "/Users/martinmac/Big_Data_Prak_Lani/data/kl/kl_total.csv",
source = "com.databricks.spark.csv",
schema = klSchema,
header="true", delimiter = ";")
inDf <- select(inDf, "STATIONS_ID","MESS_DATUM","QUALITAETS_NIVEAU","SONNENSCHEINDAUER","SCHNEEHOEHE","LUFTTEMPERATUR")
SparkR::head(inDf)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/siebenschlaefertag.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/siebenschlaefertag.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/siebenschlaefertag.R', echo=TRUE)
ddply(df7, SID, correlation, allMeanSONNE,allMeanSONNEw)
corSonne <- ddply(df7, .(SID), correlation, "allMeanSONNE", "allMeanSONNEw")
corSonne <- ddply(df7, .(SID), correlation, "allMeanSONNE", "allMeanSONNEw")
SparkR::head(corSonne)
write.df(joinedDf, "/Users/martinmac/Big_Data_Prak_Lani/siebenschlaefertag.csv", "com.databricks.spark.csv", "overwrite")
SparkR::head(joinedDf)
SparkR::head(joinedDf)
write.df(joinedDf, "/Users/martinmac/Big_Data_Prak_Lani/siebenschlaefertag.csv", "com.databricks.spark.csv", "overwrite")
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/januar_hell_sommer_heiss.R', echo=TRUE)
januarMeanDf_y <- agg(group_by(januar, "STATIONS_ID","YEAR"), meanSONNE = mean(januar$SONNENSCHEINDAUER),meanSCHNEE = mean(januar$SCHNEEHOEHE))
SparkR::head(januarMeanDf_y)
# STATIONS_ID YEAR meanSONNE  meanSCHNEE
# 1        2783 1976 1.3612903  0.87096774
# 2        3631 2000 1.5967742  0.03225806
# 3        2444 1919 0.9193548  1.25806452
# 4        3621 1970 0.9096774 11.06451613
# 5         642 1993 1.7516129  0.00000000
# join januar dfs
# januarDf <- select(januarDf, alias(januarDf$STATIONS_ID, "SID_JAN")) alias doesn't work for S4
januarDf <- join(januarMeanDf_y,januarMeanDf, januarMeanDf_y$STATIONS_ID == januarMeanDf$id)
januarDf <- select(januarDf, "STATIONS_ID","YEAR","meanSONNE","meanSCHNEE","allMeanSONNE","allMeanSCHNEE")
januarDf <- withColumnRenamed(januarDf, "STATIONS_ID", "SID_JAN")
januarDf <- withColumnRenamed(januarDf, "YEAR", "YEAR_JAN")
SparkR::nrow(januarDf)
SparkR::head(januarDf)
# SID_JAN YEAR_JAN meanSONNE meanSCHNEE allMeanSONNE allMeanSCHNEE
# 1    2831     1950 2.3000000  0.7419355     1.659553      6.057072
# 2    2831     1951 0.8935484  9.9354839     1.659553      6.057072
# 3    2831     1952 1.2516129  5.0967742     1.659553      6.057072
# 4    2831     1953 0.4838710  5.6774194     1.659553      6.057072
# 5    2831     1958 2.4258065  3.4516129     1.659553      6.057072
# calculate means of temp for each station and in each year
sommerMeanDf_y <- agg(group_by(sommer, "STATIONS_ID","YEAR"), meanTEMP = mean(sommer$LUFTTEMPERATUR))
sommerDf <- join(sommerMeanDf_y,sommerMeanDf, sommerMeanDf_y$STATIONS_ID == sommerMeanDf$id)
sommerDf <- select(sommerDf, "STATIONS_ID","YEAR","meanTEMP","allMeanTEMP")
sommerDf <- withColumnRenamed(sommerDf, "STATIONS_ID", "SID_SOM")
sommerDf <- withColumnRenamed(sommerDf, "YEAR", "YEAR_SOM")
SparkR::nrow(sommerDf)
SparkR::head(sommerDf)
# left join 2 dataframes by station AND year, left one is the smaller dataframe (januar)
df <- join(januarDf,sommerDf, januarDf$SID_JAN == sommerDf$SID_SOM & januarDf$YEAR_JAN == sommerDf$YEAR_SOM)
SparkR::head(df)
SparkR::nrow(df)
# SID_JAN YEAR_JAN meanSONNE meanSCHNEE allMeanSONNE allMeanSCHNEE SID_SOM YEAR_SOM meanTEMP allMeanTEMP
# 1     150     1997 0.6290323  9.1612903     1.362160      1.395161     150     1997 18.63043    17.91539
# 2     232     1963 2.5161290 18.6774194     1.950775      3.834915     232     1963 16.96957    17.03808
# 3     259     1964 1.1096774  0.6129032     1.227680      2.697190     259     1964 18.73696    17.74899
# 4     480     1987 2.1258065  5.3548387     1.244841      4.671975     480     1987 14.85978    15.76203
# 5     502     1973 0.8000000  0.4838710     1.171464      7.551696     502     1973 16.42391    16.16552
df <- withColumnRenamed(df, "SID_JAN", "SID")
df <- withColumnRenamed(df, "YEAR_JAN", "YEAR")
# stimmt es in Deutschland?
# OUTPUT: # all three parameters are true and # of all cases
stimmtDf <- where(df, df$meanSONNE > df$allMeanSONNE & df$meanSCHNEE > df$allMeanSCHNEE & df$meanTEMP > df$allMeanTEMP)
SparkR::head(stimmtDf)
# take(stimmtDf,5L)
#    SID YEAR meanSONNE meanSCHNEE allMeanSONNE allMeanSCHNEE SID_SOM YEAR_SOM meanTEMP allMeanTEMP
# 1 1032 1963  1.638710   5.935484     1.343088      1.396313    1032     1963 17.11250    16.50116
# 2 2074 2009  3.558065   1.677419     2.257631      1.641577    2074     2009 17.16196    17.15498
# 3 3096 1995  1.632258   9.322581     1.480108      7.997611    3096     1995 17.10217    15.29413
# 4 3485 2002  1.812903   2.354839     1.647926      2.274194    3485     2002 17.72826    17.16801
# 5 3730 1937  3.051613  31.774194     2.498264     30.415680    3730     1937 14.86630    14.74469
# nrow(januarMeanDf_y)
# [1] 15368
# nrow(sommerMeanDf_y)
# [1] 15368
# stimmt in Deutschland? (overall)
a <- count(stimmtDf)
a
# [1] 925
b <- count(df)
b
# [1] 14996
stimmit_de_overall <- a / b
stimmit_de_overall
# [1] 0.06168312
# stimmt in Deutschland? (station)
cAllDf <- agg(group_by(df, "SID"), cAll = n(df$YEAR))
SparkR::head(cAllDf)
# take(cAllDf,5L)
# SID cAll
# 1 3031   33
# 2 3231   24
# 3 3631   68
# 4 2831   12
# 5  232   68
cOverMeanDf <- agg(group_by(stimmtDf, "SID"), cOverMean = n(stimmtDf$YEAR))
SparkR::head(cOverMeanDf)
# take(cOverMeanDf,5L)
# SID cOverMean
# 1 3231         2
# 2 3031         2
# 3 3631         5
# 4 2831         1
# 5 1032         1
cOverMeanDf <- withColumnRenamed(cOverMeanDf, "SID", "ID")
## read station data
stationDf <- read.df(sqlContext,
"/Users/martinmac/Big_Data_Prak_Lani/data/kl/KL_Tageswerte_Beschreibung_Stationen4.txt",
"com.databricks.spark.csv",
metaSchema,
header="true", delimiter = "\t")
SparkR::nrow(stationDf)
# [1] 585
# export stimmt for each station for visualisation
cFinal <- join(cAllDf, cOverMeanDf, cAllDf$SID == cOverMeanDf$ID)
cFinal$stimmt <- cFinal$cOverMean / cFinal$cAll
cFinal <- select(cFinal, cFinal$SID, cFinal$cAll, cFinal$cOverMean, cFinal$stimmt)
cFinal <- join(cFinal, stationDf, cFinal$SID == stationDf$STATIONS_ID)
cFinal <- arrange(cFinal, desc(cFinal$stimmt))
SparkR::head(cFinal)
SparkR::nrow(cFinal)
#    SID cAll cOverMean    stimmt STATIONS_ID von_datum bis_datum Statationshoehe longitude latitude
# 1 6170    3         1 0.3333333        6170  20000201  20150422              40   52.0192  14.7254
# 2 4367    3         1 0.3333333        4367  19920401  20061231             175   52.0780   9.5520
# 3  474    3         1 0.3333333         474  19590101  19860930             599   48.1252   9.7639
# 4 4847    3         1 0.3333333        4847  19700101  19751231             500   51.3629   9.6902
# 5 2796    3         1 0.3333333        2796  20000601  20150422              40   53.9156  12.2790
# Stationsname             Bundesland Lage
# 1                   Coschen            Brandenburg    O
# 2 Salzhemmendorf-Lauenstein          Niedersachsen    N
# 3     Warthausen-Birkenhard   Baden-W\xfcrttemberg    S
# 4                 Steinberg          Niedersachsen    N
# 5         Laage (Flugplatz) Mecklenburg-Vorpommern    O
sOverMean <- sum(cOverMean)
sOverMean
exportCsv <- select(cFinal, "cAll", "cOverMean", "stimmt", "longitude", "latitude", "Stationsname", "Bundesland", "Lage","Statationshoehe","von_datum","bis_datum")
# stimmt es in N/S/W/O?: group_by Lage
stimmtLageDf <- agg(group_by(exportCsv,"Lage"), stimmtLage = sum(exportCsv$cOverMean) / sum(exportCsv$cAll))
SparkR::head(stimmtLageDf)
# take(stimmtLageDf,4L)
# Lage stimmtLage
# 1    N 0.05661502
# 2    O 0.07606608
# 3    S 0.06208670
# 4    W 0.05538547
write.df(exportCsv, "/Users/martinmac/Big_Data_Prak_Lani/januar_hell_sommer_heiss.csv", "com.databricks.spark.csv", "overwrite")
# OUTPUT: /Users/martinmac/Big_Data_Prak_Lani/januar_hell_sommer_heiss.csv
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
sOverMean <- sum(cFinal$cOverMean)
sOverMean
?sum
sOverMean <- sum(cFinal$cOverMean)
sOverMean
sOverMean <- SparkR::summarize(cFinal)
SparkR::summarize(cFinal)
SparkR::summary(cFinal$cOverMean)
SparkR::summary(cFinal)
SparkR::summarize(cFinal$cOverMean)
getwd()
source('~/Country-lore-analysis-Germany/set_sqlContext.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/schemata.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/siebenschlaefertag.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/siebenschlaefertag.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/analyse_scripts/siebenschlaefertag_30.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/analyse_scripts/siebenschlaefertag_30.R', echo=TRUE)
s <- filter(sieben, corSONNEz1<0)
s
source('~/Country-lore-analysis-Germany/analyse_scripts/tropfen_januar_schnee_mai_30.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/analyse_scripts/tropfen_januar_schnee_mai_30.R', echo=TRUE)
source('~/Country-lore-analysis-Germany/analyse_scripts/tropfen_januar_schnee_mai_30.R', echo=TRUE)
head(tropfen)
source('~/Country-lore-analysis-Germany/analyse_scripts/tropfen_januar_schnee_mai_30.R', echo=TRUE)
head(tropfen)
